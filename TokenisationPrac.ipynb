{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus='''\n",
    "So, hello I am Mawiya Manzar, currently pursuing BCA, Why? Coz that was the only option that allowed me to have a career in IT industry. Well currently\n",
    "I am no one and also not wanting to be someone, here I am trying to optimize everything that I am doing to achieve better result, as time is passing by fast\n",
    "and I am trying and trying very hard!. I am Learning NLP from Krish Naik's Udemy course and I am loving it. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nSo, hello I am Mawiya Manzar, currently pursuing BCA, Why?',\n",
       " 'Coz that was the only option that allowed me to have a career in IT industry.',\n",
       " 'Well currently\\nI am no one and also not wanting to be someone, here I am trying to optimize everything that I am doing to achieve better result, as time is passing by fast\\nand I am trying and trying very hard!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So',\n",
       " ',',\n",
       " 'hello',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Mawiya',\n",
       " 'Manzar',\n",
       " ',',\n",
       " 'currently',\n",
       " 'pursuing',\n",
       " 'BCA',\n",
       " ',',\n",
       " 'Why',\n",
       " '?',\n",
       " 'Coz',\n",
       " 'that',\n",
       " 'was',\n",
       " 'the',\n",
       " 'only',\n",
       " 'option',\n",
       " 'that',\n",
       " 'allowed',\n",
       " 'me',\n",
       " 'to',\n",
       " 'have',\n",
       " 'a',\n",
       " 'career',\n",
       " 'in',\n",
       " 'IT',\n",
       " 'industry',\n",
       " '.',\n",
       " 'Well',\n",
       " 'currently',\n",
       " 'I',\n",
       " 'am',\n",
       " 'no',\n",
       " 'one',\n",
       " 'and',\n",
       " 'also',\n",
       " 'not',\n",
       " 'wanting',\n",
       " 'to',\n",
       " 'be',\n",
       " 'someone',\n",
       " ',',\n",
       " 'here',\n",
       " 'I',\n",
       " 'am',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'optimize',\n",
       " 'everything',\n",
       " 'that',\n",
       " 'I',\n",
       " 'am',\n",
       " 'doing',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'better',\n",
       " 'result',\n",
       " ',',\n",
       " 'as',\n",
       " 'time',\n",
       " 'is',\n",
       " 'passing',\n",
       " 'by',\n",
       " 'fast',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'trying',\n",
       " 'and',\n",
       " 'trying',\n",
       " 'very',\n",
       " 'hard',\n",
       " '!',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Learning',\n",
       " 'NLP',\n",
       " 'from',\n",
       " 'Krish',\n",
       " 'Naik',\n",
       " \"'s\",\n",
       " 'Udemy',\n",
       " 'course',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'loving',\n",
       " 'it',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So',\n",
       " ',',\n",
       " 'hello',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Mawiya',\n",
       " 'Manzar',\n",
       " ',',\n",
       " 'currently',\n",
       " 'pursuing',\n",
       " 'BCA',\n",
       " ',',\n",
       " 'Why',\n",
       " '?',\n",
       " 'Coz',\n",
       " 'that',\n",
       " 'was',\n",
       " 'the',\n",
       " 'only',\n",
       " 'option',\n",
       " 'that',\n",
       " 'allowed',\n",
       " 'me',\n",
       " 'to',\n",
       " 'have',\n",
       " 'a',\n",
       " 'career',\n",
       " 'in',\n",
       " 'IT',\n",
       " 'industry',\n",
       " '.',\n",
       " 'Well',\n",
       " 'currently',\n",
       " 'I',\n",
       " 'am',\n",
       " 'no',\n",
       " 'one',\n",
       " 'and',\n",
       " 'also',\n",
       " 'not',\n",
       " 'wanting',\n",
       " 'to',\n",
       " 'be',\n",
       " 'someone',\n",
       " ',',\n",
       " 'here',\n",
       " 'I',\n",
       " 'am',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'optimize',\n",
       " 'everything',\n",
       " 'that',\n",
       " 'I',\n",
       " 'am',\n",
       " 'doing',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'better',\n",
       " 'result',\n",
       " ',',\n",
       " 'as',\n",
       " 'time',\n",
       " 'is',\n",
       " 'passing',\n",
       " 'by',\n",
       " 'fast',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'trying',\n",
       " 'and',\n",
       " 'trying',\n",
       " 'very',\n",
       " 'hard',\n",
       " '!.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Learning',\n",
       " 'NLP',\n",
       " 'from',\n",
       " 'Krish',\n",
       " 'Naik',\n",
       " \"'\",\n",
       " 's',\n",
       " 'Udemy',\n",
       " 'course',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'loving',\n",
       " 'it',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)\n",
    "#it will even tokenise the ('s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So',\n",
       " ',',\n",
       " 'hello',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Mawiya',\n",
       " 'Manzar',\n",
       " ',',\n",
       " 'currently',\n",
       " 'pursuing',\n",
       " 'BCA',\n",
       " ',',\n",
       " 'Why',\n",
       " '?',\n",
       " 'Coz',\n",
       " 'that',\n",
       " 'was',\n",
       " 'the',\n",
       " 'only',\n",
       " 'option',\n",
       " 'that',\n",
       " 'allowed',\n",
       " 'me',\n",
       " 'to',\n",
       " 'have',\n",
       " 'a',\n",
       " 'career',\n",
       " 'in',\n",
       " 'IT',\n",
       " 'industry.',\n",
       " 'Well',\n",
       " 'currently',\n",
       " 'I',\n",
       " 'am',\n",
       " 'no',\n",
       " 'one',\n",
       " 'and',\n",
       " 'also',\n",
       " 'not',\n",
       " 'wanting',\n",
       " 'to',\n",
       " 'be',\n",
       " 'someone',\n",
       " ',',\n",
       " 'here',\n",
       " 'I',\n",
       " 'am',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'optimize',\n",
       " 'everything',\n",
       " 'that',\n",
       " 'I',\n",
       " 'am',\n",
       " 'doing',\n",
       " 'to',\n",
       " 'achieve',\n",
       " 'better',\n",
       " 'result',\n",
       " ',',\n",
       " 'as',\n",
       " 'time',\n",
       " 'is',\n",
       " 'passing',\n",
       " 'by',\n",
       " 'fast',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'trying',\n",
       " 'and',\n",
       " 'trying',\n",
       " 'very',\n",
       " 'hard',\n",
       " '!',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Learning',\n",
       " 'NLP',\n",
       " 'from',\n",
       " 'Krish',\n",
       " 'Naik',\n",
       " \"'s\",\n",
       " 'Udemy',\n",
       " 'course',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'loving',\n",
       " 'it',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TreebankWordTokenizer().tokenize(corpus)\n",
    "#it will only include the last full stop as token."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
